{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore, CoherenceModel, Phrases\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"PATH/TO/PREPROCESSED_DATA.csv\"\n",
    "text_column = \"concatenated_text\"\n",
    "\n",
    "num_topics_range = list(range(15, 251, 5))\n",
    "alpha = 0.01\n",
    "beta = 0.1\n",
    "passes = 50\n",
    "random_state = 69\n",
    "\n",
    "selected_topic_counts = [50]\n",
    "\n",
    "output_root = \"PATH/TO/LDA_OUTPUTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics_to_documents(lda_model, corpus, data):\n",
    "    document_topics = []\n",
    "    for doc_bow in corpus:\n",
    "        doc_topics = lda_model.get_document_topics(doc_bow)\n",
    "        doc_topics = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
    "        most_probable_topic = doc_topics[0][0] if doc_topics else None\n",
    "        document_topics.append(most_probable_topic)\n",
    "    data = data.copy()\n",
    "    data['Assigned_Topic'] = document_topics\n",
    "    topic_counts = data['Assigned_Topic'].value_counts()\n",
    "    return data.sort_values(by='Assigned_Topic'), topic_counts\n",
    "\n",
    "\n",
    "def save_topics(lda_model, num_topics, directory, topic_counts):\n",
    "    topics = lda_model.print_topics(num_topics=num_topics, num_words=15)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    with open(os.path.join(directory, f'{num_topics}_topics.csv'), 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Topic ID', 'Topics', 'Post Count'])\n",
    "        for topic_id, topic in enumerate(topics):\n",
    "            writer.writerow([topic_id, topic, topic_counts.get(topic_id, 0)])\n",
    "\n",
    "\n",
    "def topic_cosine_similarity(lda_model):\n",
    "    topic_word_matrix = lda_model.get_topics()\n",
    "    sim_matrix = cosine_similarity(topic_word_matrix)\n",
    "    np.fill_diagonal(sim_matrix, 0)\n",
    "    return float(np.sum(sim_matrix) / (lda_model.num_topics * (lda_model.num_topics - 1)))\n",
    "\n",
    "\n",
    "def find_elbow_point(x_values, y_values):\n",
    "    if len(x_values) < 3:\n",
    "        return None\n",
    "    x = np.array(x_values, dtype=float)\n",
    "    y = np.array(y_values, dtype=float)\n",
    "    line = np.linspace(y[0], y[-1], num=len(y))\n",
    "    distances = np.abs(y - line)\n",
    "    idx = int(np.argmax(distances))\n",
    "    return int(x[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "texts = data[text_column].astype(str).apply(lambda x: x.split())\n",
    "\n",
    "bigram = Phrases(texts, min_count=5, threshold=100)\n",
    "texts_bigram = [bigram[doc] for doc in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts_bigram)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_bigram]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores = []\n",
    "cosine_scores = []\n",
    "\n",
    "for num_topics in num_topics_range:\n",
    "    print(f\"Training {num_topics} topics...\")\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus,\n",
    "        num_topics=num_topics,\n",
    "        id2word=dictionary,\n",
    "        alpha=alpha,\n",
    "        eta=beta,\n",
    "        passes=passes,\n",
    "        workers=min(8, 9),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=texts_bigram, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    cosine_sim = topic_cosine_similarity(lda_model)\n",
    "\n",
    "    coherence_scores.append(coherence)\n",
    "    cosine_scores.append(cosine_sim)\n",
    "    print(f\"  coherence={coherence:.4f}, cosine_similarity={cosine_sim:.4f}\")\n",
    "\n",
    "elbow_topics = find_elbow_point(num_topics_range, cosine_scores)\n",
    "print(f\"Elbow topic count (cosine similarity): {elbow_topics}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(num_topics_range, coherence_scores, marker='o')\n",
    "plt.title('Coherence vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence (c_v)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(num_topics_range, cosine_scores, marker='o', color='r')\n",
    "if elbow_topics:\n",
    "    plt.axvline(elbow_topics, color='gray', linestyle='--', label=f'Elbow \u2248 {elbow_topics}')\n",
    "    plt.legend()\n",
    "plt.title('Average Cosine Similarity vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Average Cosine Similarity')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_root, exist_ok=True)\n",
    "final_topic_counts = list(selected_topic_counts)\n",
    "if elbow_topics and elbow_topics not in final_topic_counts:\n",
    "    final_topic_counts.append(elbow_topics)\n",
    "\n",
    "for k in final_topic_counts:\n",
    "    print(f\"Training final model with {k} topics...\")\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus,\n",
    "        num_topics=k,\n",
    "        id2word=dictionary,\n",
    "        alpha=alpha,\n",
    "        eta=beta,\n",
    "        passes=passes,\n",
    "        workers=min(8, 9),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    directory = os.path.join(output_root, f\"{k}\")\n",
    "    updated_data, topic_counts = assign_topics_to_documents(lda_model, corpus, data)\n",
    "    save_topics(lda_model, k, directory, topic_counts)\n",
    "    updated_data.to_csv(os.path.join(directory, f'{k}_annotated_data.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}